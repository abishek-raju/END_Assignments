NLP Loss Functions

1.Data Cleaning:

2.Model Architecture:
https://www.linkedin.com/pulse/understanding-attention-all-you-need-abishek-raju/?trackingId=Qm11qBdpT1%2BWSlACVKycpg%3D%3D

3.Loss Function:

4.Data Preparation:

5.Python Code Embedding:

6.Evaluation Metrics:

7."25"  example output from your model

8.attention graph/images between text and "python-code"


References:
https://towardsdatascience.com/perplexity-in-language-models-87a196019a94
https://arxiv.org/pdf/1405.2061.pdf