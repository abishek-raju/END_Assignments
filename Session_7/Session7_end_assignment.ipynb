{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session7_end_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAK8dvGkGMsf",
        "outputId": "e68d8421-0210-4d9e-b165-bf9a0cc6ff61"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=92bae75e37b0477403e2454705fa8ba8186c94cdfb78a1923ffface9abbc2664\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZHjety6EGMT"
      },
      "source": [
        "url = \"http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\"\n",
        "import wget\n",
        "\n",
        "wget.download(url, 'stanfordSentimentTreebank.zip')\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"stanfordSentimentTreebank.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"stanfordSentimentTreebank\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJNzOznRHtVH"
      },
      "source": [
        "data_sentences_txt_path=\"./stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt\"\n",
        "sentiment_labels_txt_path=\"./stanfordSentimentTreebank/stanfordSentimentTreebank/sentiment_labels.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-h17nreKHPY"
      },
      "source": [
        "    def get_merged_dataset(sst_dir):\n",
        "        sentiment_labels = pd.read_csv(os.path.join(sst_dir, \"sentiment_labels.txt\"), sep=\"|\")\n",
        "        sentence_ids = pd.read_csv(os.path.join(sst_dir, \"datasetSentences.txt\"), sep=\"\\t\")\n",
        "        dictionary = pd.read_csv(os.path.join(sst_dir, \"dictionary.txt\"), sep=\"|\", names=['phrase', 'phrase ids'])\n",
        "        train_test_split = pd.read_csv(os.path.join(sst_dir, \"datasetSplit.txt\"))\n",
        "        sentence_phrase_merge = pd.merge(sentence_ids, dictionary, left_on='sentence', right_on='phrase')\n",
        "        sentence_phrase_split = pd.merge(sentence_phrase_merge, train_test_split, on='sentence_index')\n",
        "        return pd.merge(sentence_phrase_split, sentiment_labels, on='phrase ids').sample(frac=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFAE1Jw2u92"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "# df=get_merged_dataset(\"./stanfordSentimentTreebank/stanfordSentimentTreebank\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GKX7Us5ncryD",
        "outputId": "daf32dd0-d9af-43ec-fba0-74ffc885e728"
      },
      "source": [
        "sst_dir = \"./stanfordSentimentTreebank/stanfordSentimentTreebank\"\n",
        "df_phrases = pd.read_csv(os.path.join(sst_dir, \"dictionary.txt\"), sep='|', header=None)\n",
        "df_labels = pd.read_csv(os.path.join(sst_dir, \"sentiment_labels.txt\"), sep='|')\n",
        "\n",
        "df = pd.merge(df_phrases, df_labels, how='inner', left_on=1, right_on='phrase ids')\n",
        "df.rename(columns={0: 'sentence'}, inplace=True)\n",
        "df.sentence[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VoHlW1w029W0",
        "outputId": "70819037-23db-477f-dad9-c21e9bb305bc"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>1</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "      <td>22935</td>\n",
              "      <td>0.52778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "      <td>18235</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "      <td>179257</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "      <td>22936</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence       1  phrase ids  sentiment values\n",
              "0            !       0           0           0.50000\n",
              "1          ! '   22935       22935           0.52778\n",
              "2         ! ''   18235       18235           0.50000\n",
              "3       ! Alas  179257      179257           0.44444\n",
              "4  ! Brilliant   22936       22936           0.86111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUcBHDTAWhTz"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x8KaOsEI-lD",
        "outputId": "46fbb0a6-6e93-46d8-c280-14fbb8222006"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 1, 'phrase ids', 'sentiment values'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm95fyUNIzSy",
        "outputId": "7152a4d4-be37-4676-f9d1-9223ce1b2031"
      },
      "source": [
        "df[[\"sentence\",\"sentiment values\"]].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(239232, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining Sentiment as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). Sentence is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1ba673-cc25-403e-94a5-97570cc221fe"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3bd8349c48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Sentiment = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhr_p0j3Lc5Y"
      },
      "source": [
        "fields = [('sentence', Sentence),('sentiment',Sentiment)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgGnBTLBL0Yw"
      },
      "source": [
        "def discretize_label(label):\n",
        "  if label <= 0.2: return 0\n",
        "  if label <= 0.4: return 1\n",
        "  if label <= 0.6: return 2\n",
        "  if label <= 0.8: return 3\n",
        "  return 4"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02AJ4-XELk2F"
      },
      "source": [
        "example = [data.Example.fromlist([df.sentence[i],discretize_label(df[\"sentiment values\"][i])], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcF7cQjNek9O"
      },
      "source": [
        "# train = [data.Example.fromlist([df.sentence[i],discretize_label(df[\"sentiment values\"][i])], fields) for i in range(df.shape[0]) if df.splitset_label[i] == 1] "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py4n9dK0fGCb"
      },
      "source": [
        "# test = [data.Example.fromlist([df.sentence[i],discretize_label(df[\"sentiment values\"][i])], fields) for i in range(df.shape[0]) if df.splitset_label[i] == 1] "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS1yLKiDTTF7"
      },
      "source": [
        "sst_dataset = data.Dataset(example, fields)\n",
        "# train = data.Dataset(train, fields)\n",
        "# test = data.Dataset(test, fields)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6Nouquf4tq"
      },
      "source": [
        "(train, valid) = sst_dataset.split(split_ratio=[0.85, 0.15])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvXdon0Kf5st"
      },
      "source": [
        "Sentence.build_vocab(train)\n",
        "Sentiment.build_vocab(train)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td--SDsggIcL",
        "outputId": "752dc270-8947-4790-e884-928d68fb4cda"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Sentiment.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Sentiment.vocab.stoi)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  20824\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('the', 65188), (',', 60177), ('a', 46544), ('of', 44506), ('and', 44192), ('.', 32372), ('to', 31654), ('-', 30786), (\"'s\", 23948), ('is', 19519)]\n",
            "Labels :  defaultdict(<function _default_unk_index at 0x7f3b87fccd90>, {2: 0, 3: 1, 1: 2, 4: 3, 0: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 200\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d804ba-d1f6-4e01-e42a-0caa2e657426"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(20824, 300)\n",
            "  (encoder): LSTM(300, 200, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")\n",
            "The model has 6,971,405 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.sentence   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.sentiment)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.sentiment)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.sentiment)\n",
        "            acc = binary_accuracy(predictions, batch.sentiment)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bddce69-04d7-4982-b96c-9e357a992088"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.372 | Train Acc: 53.37%\n",
            "\t Val. Loss: 1.328 |  Val. Acc: 57.03% \n",
            "\n",
            "\tTrain Loss: 1.305 | Train Acc: 59.54%\n",
            "\t Val. Loss: 1.299 |  Val. Acc: 60.19% \n",
            "\n",
            "\tTrain Loss: 1.273 | Train Acc: 62.92%\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 61.38% \n",
            "\n",
            "\tTrain Loss: 1.252 | Train Acc: 65.08%\n",
            "\t Val. Loss: 1.279 |  Val. Acc: 62.31% \n",
            "\n",
            "\tTrain Loss: 1.236 | Train Acc: 66.82%\n",
            "\t Val. Loss: 1.274 |  Val. Acc: 62.73% \n",
            "\n",
            "\tTrain Loss: 1.223 | Train Acc: 68.12%\n",
            "\t Val. Loss: 1.272 |  Val. Acc: 62.94% \n",
            "\n",
            "\tTrain Loss: 1.213 | Train Acc: 69.22%\n",
            "\t Val. Loss: 1.268 |  Val. Acc: 63.43% \n",
            "\n",
            "\tTrain Loss: 1.204 | Train Acc: 70.09%\n",
            "\t Val. Loss: 1.269 |  Val. Acc: 63.32% \n",
            "\n",
            "\tTrain Loss: 1.197 | Train Acc: 70.87%\n",
            "\t Val. Loss: 1.268 |  Val. Acc: 63.43% \n",
            "\n",
            "\tTrain Loss: 1.190 | Train Acc: 71.48%\n",
            "\t Val. Loss: 1.268 |  Val. Acc: 63.38% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}